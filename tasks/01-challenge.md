# ğŸ›¡ï¸ Desafio de Engenharia de DetecÃ§Ã£o de Fraude UberEats

## VisÃ£o Geral do Desafio

**DuraÃ§Ã£o**: 2-3 dias  
**Dificuldade**: NÃ­vel Engenheiro SÃªnior  
**Tools Permitidas**: Assistentes de IA (Claude Code, GitHub Copilot, etc.), pesquisa na internet, documentaÃ§Ã£o  
**Cloud Services**: VersÃµes trial de cloud services sÃ£o encorajadas, alternativas open-source permitidas, sem restriÃ§Ãµes na escolha de tools  
**EntregÃ¡vel Final**: Pipeline de detecÃ§Ã£o de fraude totalmente funcional rodando em seu repository privado do GitHub  

## ğŸ¯ DeclaraÃ§Ã£o da MissÃ£o

VocÃª Ã© responsÃ¡vel por reconstruir o sistema de detecÃ§Ã£o de fraude do UberEats do zero, usando os componentes e arquitetura demonstrados em aula. No entanto, o codebase fornecido contÃ©m vÃ¡rias **issues deliberadas** que vocÃª deve identificar, isolar e corrigir para deixar o sistema totalmente operacional.

Este desafio simula cenÃ¡rios do mundo real onde vocÃª herda um sistema parcialmente funcionando e deve fazer troubleshooting, debug e otimizÃ¡-lo para uso em produÃ§Ã£o.

## ğŸ“‹ Requisitos do Desafio

### Fase 1: Setup do Environment & AnÃ¡lise Inicial (Dia 1)

#### 1.1 Setup do Repository
- [ ] Criar um **repository privado no GitHub** chamado `fraud-detection-challenge`
- [ ] Clonar a arquitetura base do sistema de detecÃ§Ã£o de fraude
- [ ] Configurar environment virtual Python adequado
- [ ] Configurar todos os services externos necessÃ¡rios:
  - **Cloud Services**: Usar versÃµes trial (Confluent Cloud, Qdrant Cloud, OpenAI API)
  - **Alternativas Open Source**: Kafka local, vector DB local, Redis local, PostgreSQL
  - **Sem RestriÃ§Ãµes**: Escolher qualquer combinaÃ§Ã£o que funcione para seu environment

#### 1.2 AvaliaÃ§Ã£o Inicial do Sistema
- [ ] Executar o health check do sistema e documentar todos os componentes com falha
- [ ] Identificar as mensagens de erro especÃ­ficas e pontos de falha
- [ ] Criar um **Issue Log** detalhado documentando cada problema encontrado
- [ ] Estimar o escopo de trabalho necessÃ¡rio para cada issue

#### 1.3 DocumentaÃ§Ã£o da Arquitetura
- [ ] Criar um diagrama de arquitetura mostrando os componentes do sistema
- [ ] Documentar o data flow esperado do Kafka atÃ© a decisÃ£o final de fraude
- [ ] Listar todas as dependÃªncias externas e seus propÃ³sitos

### Fase 2: Isolamento & ResoluÃ§Ã£o de Issues (Dia 2)

#### 2.1 Issues CrÃ­ticas para Resolver

VocÃª encontrarÃ¡ vÃ¡rias categorias de problemas que precisam de resoluÃ§Ã£o:

**ğŸš¨ Issues de ConfiguraÃ§Ã£o**
- ConfiguraÃ§Ãµes incorretas de environment variables
- Falhas de conexÃ£o com services
- Problemas de autenticaÃ§Ã£o com APIs externas

**ğŸ’£ Bugs de CÃ³digo** 
- Erros de import e dependÃªncias faltando
- Erros de lÃ³gica nos algoritmos de scoring de fraude
- Incompatibilidades de tipos de dados em Spark DataFrames
- Memory leaks em processors de streaming

**ğŸ”§ Problemas de Infraestrutura**
- Incompatibilidades de schema de database
- Issues de configuraÃ§Ã£o de tÃ³picos Kafka
- ConfiguraÃ§Ã£o incorreta de circuit breaker
- Problemas de alocaÃ§Ã£o de recursos

**ğŸ›¡ï¸ Vulnerabilidades de SeguranÃ§a**
- Credenciais hardcoded (encontrar e corrigir TODAS as instÃ¢ncias)
- Bypasses de validaÃ§Ã£o de input
- Vulnerabilidades de SQL injection
- ConfiguraÃ§Ãµes default inseguras

#### 2.2 CorreÃ§Ãµes ObrigatÃ³rias
Para cada issue que vocÃª descobrir, deve:
- [ ] **Documentar o Problema**: DescriÃ§Ã£o clara da issue
- [ ] **Root Cause Analysis**: Explicar POR QUE o problema ocorreu
- [ ] **SoluÃ§Ã£o Implementada**: Descrever sua correÃ§Ã£o com exemplos de cÃ³digo
- [ ] **VerificaÃ§Ã£o de Testing**: Provar que sua correÃ§Ã£o funciona com resultados de test
- [ ] **EstratÃ©gia de PrevenÃ§Ã£o**: Como prevenir esta issue no futuro

### Fase 3: IntegraÃ§Ã£o do Sistema & OtimizaÃ§Ã£o (Dia 3)

#### 3.1 Testing End-to-End
- [ ] Processar com sucesso dados sintÃ©ticos de detecÃ§Ã£o de fraude
- [ ] Demonstrar todos os componentes trabalhando juntos:
  - âœ… Consumo de stream Kafka
  - âœ… Processamento de Spark DataFrame
  - âœ… Algoritmos de scoring de fraude
  - âœ… AnÃ¡lise de agente IA (opcional mas pontos bonus)
  - âœ… Storage e retrieval de resultados
  - âœ… Monitoring em tempo real

#### 3.2 OtimizaÃ§Ã£o de Performance
- [ ] Otimizar configuraÃ§Ã£o do Spark para seu environment
- [ ] Implementar error handling adequado e circuit breakers
- [ ] Adicionar logging e monitoring abrangentes
- [ ] Documentar caracterÃ­sticas de performance (throughput, latency)

#### 3.3 ProntidÃ£o para ProduÃ§Ã£o
- [ ] Security hardening (eliminar todos os secrets hardcoded)
- [ ] Implementar gerenciamento adequado de configuraÃ§Ã£o
- [ ] Adicionar endpoints de health check
- [ ] Criar documentaÃ§Ã£o de deployment

## ğŸ—ï¸ Arquitetura do Sistema para Construir

### Componentes Core NecessÃ¡rios

```mermaid
graph TB
    A[Kafka Orders Stream] --> B[Spark Streaming Engine]
    B --> C[Data Enrichment Service]
    C --> D[Fraud Detection Engine]
    D --> E[Risk Scoring Algorithm]
    E --> F{High Risk?}
    F -->|Yes| G[AI Agent Analysis]
    F -->|No| H[Auto Decision]
    G --> I[Decision Engine]
    H --> I
    I --> J[Action Executor]
    I --> K[Results Storage]
    K --> L[Analytics Dashboard]
    
    M[Qdrant Vector DB] --> G
    N[Redis Cache] --> G
    O[PostgreSQL] --> K
    
    style D fill:#ff6b6b
    style G fill:#4ecdc4
    style L fill:#45b7d1
```

### Stack TecnolÃ³gico

| Componente | Technology | VersÃ£o | PropÃ³sito |
|-----------|------------|---------|---------|
| **Streaming** | Apache Spark | 4.0+ | Processamento de dados em tempo real |
| **Message Queue** | Confluent Cloud / Apache Kafka | Latest | IngestÃ£o de stream de pedidos |
| **AI Processing** | OpenAI GPT-4 / Local LLM | Latest | AnÃ¡lise inteligente de fraude |
| **Vector Database** | Qdrant Cloud / ChromaDB / FAISS | Latest | Pattern matching |
| **Cache** | Redis / Local Redis | 7+ | OtimizaÃ§Ã£o de performance |
| **Database** | PostgreSQL / SQLite | 14+ | PersistÃªncia de resultados |
| **Monitoring** | Custom + Spark UI | - | Observabilidade do sistema |

**ğŸ’¡ OpÃ§Ãµes de Service**: Use versÃµes trial de cloud services ou implante alternativas open-source localmente. Sem restriÃ§Ãµes nas escolhas de technology!

## ğŸ¯ CritÃ©rios de AvaliaÃ§Ã£o

### ExcelÃªncia TÃ©cnica (40 pontos)

**Qualidade do CÃ³digo (15 pontos)**
- CÃ³digo limpo, legÃ­vel e bem estruturado
- Error handling e logging adequados
- Design patterns e arquitetura apropriados
- DocumentaÃ§Ã£o e comentÃ¡rios no cÃ³digo

**Habilidades de Problem-Solving (15 pontos)**
- Capacidade de identificar e isolar issues complexas
- Abordagem sistemÃ¡tica de debugging
- SoluÃ§Ãµes criativas para desafios tÃ©cnicos
- CompreensÃ£o das root causes

**IntegraÃ§Ã£o do Sistema (10 pontos)**
- Todos os componentes funcionando juntos perfeitamente
- Data flow adequado atravÃ©s de todo o pipeline
- Processamento de transaÃ§Ã£o end-to-end bem-sucedido

### PrÃ¡ticas de Engenharia (30 pontos)

**DocumentaÃ§Ã£o (10 pontos)**
- DocumentaÃ§Ã£o clara de tracking e resoluÃ§Ã£o de issues
- Diagramas de arquitetura e especificaÃ§Ãµes tÃ©cnicas
- InstruÃ§Ãµes de setup e deployment
- ComentÃ¡rios no cÃ³digo e arquivos README

**Testing & ValidaÃ§Ã£o (10 pontos)**
- Testing abrangente das correÃ§Ãµes
- ValidaÃ§Ã£o de performance e benchmarking
- Tratamento de edge cases
- Testing de confiabilidade do sistema

**Security & Best Practices (10 pontos)**
- Todas as vulnerabilidades de security identificadas e corrigidas
- Gerenciamento adequado de secrets
- ValidaÃ§Ã£o e sanitizaÃ§Ã£o de input
- ConfiguraÃ§Ã£o de security pronta para produÃ§Ã£o

### InovaÃ§Ã£o & OtimizaÃ§Ã£o (20 pontos)

**OtimizaÃ§Ã£o de Performance (10 pontos)**
- Tuning do sistema e otimizaÃ§Ã£o de recursos
- Algoritmos e estruturas de dados eficientes
- ImplementaÃ§Ã£o de monitoring e observabilidade
- ConsideraÃ§Ãµes de escalabilidade

**Features Adicionais (10 pontos)**
- Monitoring e alerting aprimorados
- Error handling e recovery melhorados
- Algoritmos avanÃ§ados de detecÃ§Ã£o de fraude
- Melhorias na experiÃªncia do usuÃ¡rio

### Entrega & ComunicaÃ§Ã£o (10 pontos)

**Gerenciamento de Projeto (5 pontos)**
- Cumprimento de prazos e milestones
- Abordagem organizada para problem-solving
- Tracking e reporting de progresso

**ComunicaÃ§Ã£o (5 pontos)**
- DocumentaÃ§Ã£o e explicaÃ§Ãµes claras
- ApresentaÃ§Ã£o profissional das soluÃ§Ãµes
- Uso efetivo de tools de IA e recursos

## ğŸ“š Materiais de ReferÃªncia

### Acesso Ã  DocumentaÃ§Ã£o
- DocumentaÃ§Ã£o completa do sistema na pasta `/docs`
- Guias de arquitetura para cada componente
- Templates de configuraÃ§Ã£o e exemplos
- Guias de troubleshooting e best practices

### Recursos Externos

**DocumentaÃ§Ã£o de Cloud Services**
- [DocumentaÃ§Ã£o do Apache Spark](https://spark.apache.org/docs/latest/)
- [DocumentaÃ§Ã£o do Confluent Cloud](https://docs.confluent.io/cloud/current/)
- [DocumentaÃ§Ã£o da OpenAI API](https://platform.openai.com/docs)
- [DocumentaÃ§Ã£o do Qdrant](https://qdrant.tech/documentation/)

**DocumentaÃ§Ã£o de Alternativas Open Source**
- [DocumentaÃ§Ã£o do Apache Kafka](https://kafka.apache.org/documentation/)
- [DocumentaÃ§Ã£o do ChromaDB](https://docs.trychroma.com/)
- [DocumentaÃ§Ã£o do Redis](https://redis.io/docs/)
- [DocumentaÃ§Ã£o do PostgreSQL](https://www.postgresql.org/docs/)
- [DocumentaÃ§Ã£o do Ollama Local LLM](https://ollama.ai/)

### Tools de IA Encorajadas
- **Claude Code**: Para code review, debugging e otimizaÃ§Ã£o
- **GitHub Copilot**: Para code completion e sugestÃµes
- **ChatGPT/Claude**: Para pesquisa e assistÃªncia em problem-solving
- Qualquer outras tools de IA que te ajudem a ter sucesso

## ğŸš¨ Armadilhas Comuns a Evitar

### Issues de Environment
- **DependÃªncias Faltando**: Garantir que todos os packages Python estejam instalados
- **Conflitos de VersÃ£o**: Verificar compatibilidade entre versÃµes de packages
- **Issues de Path**: Verificar se todos os file paths e imports estÃ£o corretos
- **Conectividade de Service**: Testar todas as conexÃµes de services externos

### Issues de Processamento de Dados
- **Incompatibilidades de Schema**: Garantir que schemas de DataFrame correspondam Ã s expectativas
- **Erros de Tipo de Dados**: Tratar conversÃµes de tipo adequadamente
- **Issues de Memory**: Monitorar uso de memory em aplicaÃ§Ãµes Spark
- **State de Streaming**: Tratar operaÃ§Ãµes stateful de streaming corretamente

### Descuidos de Security
- **ExposiÃ§Ã£o de Credenciais**: Nunca fazer commit de secrets para version control
- **ValidaÃ§Ã£o de Input**: Sanitizar todos os inputs de usuÃ¡rio e dados externos
- **Controles de Acesso**: Implementar autenticaÃ§Ã£o e autorizaÃ§Ã£o adequadas
- **InformaÃ§Ãµes de Erro**: NÃ£o expor informaÃ§Ãµes sensÃ­veis em mensagens de erro

## ğŸ“Š MÃ©tricas de Sucesso

### Sistema MÃ­nimo ViÃ¡vel
- [ ] Processar com sucesso pelo menos 100 orders de test
- [ ] Accuracy de detecÃ§Ã£o de fraude > 85%
- [ ] Tempo de processamento end-to-end < 10 segundos por order
- [ ] Zero vulnerabilidades crÃ­ticas de security
- [ ] Todos os services externos adequadamente integrados

### Indicadores de ExcelÃªncia
- [ ] Throughput de processamento > 1.000 orders/minuto
- [ ] Accuracy de detecÃ§Ã£o de fraude > 95%
- [ ] Scoring de fraude sub-segundo
- [ ] Monitoring e alerting abrangentes
- [ ] ConfiguraÃ§Ã£o de deployment pronta para produÃ§Ã£o

## ğŸ† Desafios Bonus (Opcional)

### Features AvanÃ§adas (+20 pontos)
- [ ] **Dashboard em Tempo Real**: Criar interface de monitoring ao vivo
- [ ] **Framework de A/B Testing**: Implementar capacidades de comparaÃ§Ã£o de algoritmos
- [ ] **Pipeline de Training de Modelo**: Adicionar capacidade de retreinar modelos de fraude
- [ ] **Auto-scaling**: Implementar alocaÃ§Ã£o dinÃ¢mica de recursos
- [ ] **Deployment Multi-regiÃ£o**: Projetar para distribuiÃ§Ã£o geogrÃ¡fica

### Pontos de InovaÃ§Ã£o (+15 pontos)
- [ ] **DetecÃ§Ã£o de Fraude Novel**: Implementar algoritmo inovador de detecÃ§Ã£o de fraude
- [ ] **IA ExplicÃ¡vel**: Adicionar capacidades de explicaÃ§Ã£o de decisÃ£o de fraude
- [ ] **OtimizaÃ§Ã£o de Performance**: AlcanÃ§ar mÃ©tricas de performance excepcionais
- [ ] **Developer Experience**: Criar tooling e features de debugging excepcionais

## ğŸ“ EntregÃ¡veis

### Submissions ObrigatÃ³rias

1. **Repository Privado no GitHub**
   - Sistema completo de detecÃ§Ã£o de fraude funcionando
   - Todo source code com version control adequado
   - README abrangente com instruÃ§Ãµes de setup

2. **DocumentaÃ§Ã£o TÃ©cnica**
   - Issue log com problemas encontrados e soluÃ§Ãµes
   - DocumentaÃ§Ã£o de arquitetura e diagramas
   - Benchmarks de performance e notas de otimizaÃ§Ã£o

3. **Video Demo (5-10 minutos)**
   - Walkthrough do sistema mostrando todos os componentes funcionando
   - DemonstraÃ§Ã£o do pipeline de detecÃ§Ã£o de fraude
   - ExplicaÃ§Ã£o das principais decisÃµes tÃ©cnicas

4. **Retrospectiva do Desafio**
   - Qual foi a parte mais desafiadora?
   - Quais tools e recursos foram mais Ãºteis?
   - O que vocÃª faria diferente da prÃ³xima vez?

### Estrutura do Repository
```
fraud-detection-challenge/
â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o principal do projeto
â”œâ”€â”€ docs/                       # DocumentaÃ§Ã£o tÃ©cnica
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ issue-log.md
â”‚   â””â”€â”€ performance-report.md
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ streaming/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ security/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ config/                     # Arquivos de configuraÃ§Ã£o
â”œâ”€â”€ tests/                      # Test suites
â”œâ”€â”€ scripts/                    # Scripts utilitÃ¡rios
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ .env.template              # Template de environment
â””â”€â”€ challenge-retrospective.md  # Suas reflexÃµes de aprendizado
```

## ğŸ“ Objetivos de Aprendizado

Ao completar este desafio, vocÃª demonstrarÃ¡ domÃ­nio de:

### Habilidades TÃ©cnicas
- **Apache Spark**: Processamento de dados de streaming e operaÃ§Ãµes de DataFrame
- **Sistemas em Tempo Real**: ConstruÃ§Ã£o de aplicaÃ§Ãµes de streaming escalÃ¡veis e fault-tolerant
- **IntegraÃ§Ã£o de IA**: IncorporaÃ§Ã£o de machine learning e IA em data pipelines
- **IntegraÃ§Ã£o de Sistema**: ConexÃ£o de mÃºltiplos services e technologies
- **OtimizaÃ§Ã£o de Performance**: Tuning de sistemas para cargas de trabalho de produÃ§Ã£o

### PrÃ¡ticas de Engenharia
- **Debugging**: IdentificaÃ§Ã£o sistemÃ¡tica e resoluÃ§Ã£o de problemas
- **DocumentaÃ§Ã£o**: CriaÃ§Ã£o de documentaÃ§Ã£o tÃ©cnica clara e profissional
- **Security**: ImplementaÃ§Ã£o de prÃ¡ticas de security de nÃ­vel enterprise
- **Testing**: ValidaÃ§Ã£o abrangente e garantia de qualidade
- **Deployment**: ConfiguraÃ§Ã£o de sistema pronta para produÃ§Ã£o

### Habilidades Profissionais
- **Problem-Solving**: Abordagens criativas para desafios tÃ©cnicos complexos
- **ComunicaÃ§Ã£o**: ExplicaÃ§Ã£o clara de decisÃµes tÃ©cnicas e trade-offs
- **Gerenciamento de Tempo**: Entrega de projetos complexos dentro de prazos apertados
- **UtilizaÃ§Ã£o de Tools**: Uso efetivo de assistentes IA e tools de desenvolvimento

## ğŸš€ ComeÃ§ando

### Passo 1: PreparaÃ§Ã£o do Environment
```bash
# Criar seu repository de desafio
git clone <base-fraud-detection-repo>
cd fraud-detection-challenge

# Configurar environment Python
python -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
pip install -r requirements.txt

# Copiar template de environment
cp .env.template .env
# Editar .env com suas credenciais de service (cloud services ou alternativas locais)
```

### Passo 2: Health Check Inicial
```bash
# Testar conectividade bÃ¡sica do sistema
python scripts/validate_connections.py

# Executar test inicial de detecÃ§Ã£o de fraude
python run_agentic_streaming.py --test

# Documentar todos os erros em seu issue log
```

### Passo 3: ComeÃ§ar ResoluÃ§Ã£o SistemÃ¡tica
1. Priorizar issues por severidade (blocking â†’ critical â†’ minor)
2. Atacar uma issue por vez com documentaÃ§Ã£o adequada
3. Testar cada correÃ§Ã£o completamente antes de passar para a prÃ³xima
4. Fazer commit do seu progresso regularmente com mensagens claras

## ğŸ“ Suporte & Recursos

### Obtendo Ajuda
- **DocumentaÃ§Ã£o**: Verificar pasta `/docs` para guias abrangentes
- **Assistentes IA**: Aproveitar Claude Code, GitHub Copilot e outras tools de IA
- **Recursos da Comunidade**: Stack Overflow, fÃ³runs do Apache Spark, etc.
- **DocumentaÃ§Ã£o Oficial**: DocumentaÃ§Ã£o oficial de cada technology

### Best Practices
- **ComeÃ§ar Cedo**: NÃ£o subestimar tempo de setup e complexidade de issues
- **Documentar Tudo**: Manter notas detalhadas de problemas e soluÃ§Ãµes
- **Testar Frequentemente**: Validar correÃ§Ãµes imediatamente apÃ³s implementaÃ§Ã£o
- **Usar Version Control**: Fazer commit cedo e frequentemente com mensagens significativas
- **Pedir Ajuda**: Tools de IA sÃ£o explicitamente encorajadas e esperadas

## ğŸ‰ HistÃ³rias de Sucesso

Participantes anteriores do desafio relataram:
- **85% de melhoria nas habilidades de debugging** atravÃ©s de problem-solving sistemÃ¡tico
- **CompreensÃ£o mais profunda** de sistemas distribuÃ­dos e arquiteturas de streaming  
- **ConfianÃ§a aprimorada** em trabalhar com sistemas complexos multi-service
- **ExperiÃªncia valiosa** com troubleshooting de sistemas de nÃ­vel de produÃ§Ã£o
- **Projeto digno de portfolio** demonstrando capacidades de engenharia full-stack

---

**Boa sorte, e lembre-se: este desafio Ã© projetado para empurrar seus limites enquanto fornece aprendizado abrangente. Use todas as tools disponÃ­veis, seja sistemÃ¡tico em sua abordagem, e nÃ£o hesite em aproveitar assistentes IA para te ajudar a ter sucesso!** ğŸš€

**O objetivo nÃ£o Ã© apenas resolver os problemas, mas emergir como um engenheiro mais habilidoso e confiante capaz de lidar com sistemas complexos do mundo real.** ğŸ’ª